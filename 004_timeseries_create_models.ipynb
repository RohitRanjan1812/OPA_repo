{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c17937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from datetime import datetime ,timedelta\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# for data read\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# time series model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "# linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prophet\n",
    "import prophet as pt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e75e677e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRGP</th>\n",
       "      <th>FDS</th>\n",
       "      <th>SYY</th>\n",
       "      <th>RCL</th>\n",
       "      <th>PSA</th>\n",
       "      <th>FISV</th>\n",
       "      <th>HUM</th>\n",
       "      <th>SNA</th>\n",
       "      <th>EMR</th>\n",
       "      <th>CAT</th>\n",
       "      <th>...</th>\n",
       "      <th>INTC</th>\n",
       "      <th>KDP</th>\n",
       "      <th>ADP</th>\n",
       "      <th>WMB</th>\n",
       "      <th>CCL</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>DLTR</th>\n",
       "      <th>DLR</th>\n",
       "      <th>FE</th>\n",
       "      <th>ODFL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>1.182046</td>\n",
       "      <td>1.372514</td>\n",
       "      <td>0.584374</td>\n",
       "      <td>0.528572</td>\n",
       "      <td>1.704438</td>\n",
       "      <td>0.253134</td>\n",
       "      <td>0.917485</td>\n",
       "      <td>0.884942</td>\n",
       "      <td>0.890925</td>\n",
       "      <td>1.188501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425942</td>\n",
       "      <td>0.592884</td>\n",
       "      <td>0.788448</td>\n",
       "      <td>0.360051</td>\n",
       "      <td>0.664106</td>\n",
       "      <td>0.233523</td>\n",
       "      <td>0.333867</td>\n",
       "      <td>1.033731</td>\n",
       "      <td>0.974267</td>\n",
       "      <td>0.189025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>1.182046</td>\n",
       "      <td>1.370296</td>\n",
       "      <td>0.583498</td>\n",
       "      <td>0.532131</td>\n",
       "      <td>1.698507</td>\n",
       "      <td>0.253043</td>\n",
       "      <td>0.917175</td>\n",
       "      <td>0.883859</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>1.188759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426922</td>\n",
       "      <td>0.591440</td>\n",
       "      <td>0.788493</td>\n",
       "      <td>0.360219</td>\n",
       "      <td>0.664777</td>\n",
       "      <td>0.232904</td>\n",
       "      <td>0.333815</td>\n",
       "      <td>1.035587</td>\n",
       "      <td>0.970089</td>\n",
       "      <td>0.188566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>1.182046</td>\n",
       "      <td>1.368079</td>\n",
       "      <td>0.582621</td>\n",
       "      <td>0.535689</td>\n",
       "      <td>1.692577</td>\n",
       "      <td>0.252953</td>\n",
       "      <td>0.916866</td>\n",
       "      <td>0.882776</td>\n",
       "      <td>0.890409</td>\n",
       "      <td>1.189017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427902</td>\n",
       "      <td>0.589996</td>\n",
       "      <td>0.788538</td>\n",
       "      <td>0.360387</td>\n",
       "      <td>0.665447</td>\n",
       "      <td>0.232285</td>\n",
       "      <td>0.333764</td>\n",
       "      <td>1.037444</td>\n",
       "      <td>0.965912</td>\n",
       "      <td>0.188108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1.182046</td>\n",
       "      <td>1.365861</td>\n",
       "      <td>0.581744</td>\n",
       "      <td>0.539248</td>\n",
       "      <td>1.686646</td>\n",
       "      <td>0.252863</td>\n",
       "      <td>0.916557</td>\n",
       "      <td>0.881693</td>\n",
       "      <td>0.890151</td>\n",
       "      <td>1.189275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428882</td>\n",
       "      <td>0.588552</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.360555</td>\n",
       "      <td>0.666118</td>\n",
       "      <td>0.231666</td>\n",
       "      <td>0.333712</td>\n",
       "      <td>1.039300</td>\n",
       "      <td>0.961735</td>\n",
       "      <td>0.187650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1.182046</td>\n",
       "      <td>1.377001</td>\n",
       "      <td>0.577825</td>\n",
       "      <td>0.538629</td>\n",
       "      <td>1.647656</td>\n",
       "      <td>0.253997</td>\n",
       "      <td>0.944612</td>\n",
       "      <td>0.879424</td>\n",
       "      <td>0.894896</td>\n",
       "      <td>1.207841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431976</td>\n",
       "      <td>0.597422</td>\n",
       "      <td>0.772464</td>\n",
       "      <td>0.361733</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>0.231873</td>\n",
       "      <td>0.330343</td>\n",
       "      <td>1.032080</td>\n",
       "      <td>0.962353</td>\n",
       "      <td>0.178298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                TRGP       FDS       SYY       RCL       PSA      FISV  \\\n",
       "Date                                                                     \n",
       "2010-01-01  1.182046  1.372514  0.584374  0.528572  1.704438  0.253134   \n",
       "2010-01-02  1.182046  1.370296  0.583498  0.532131  1.698507  0.253043   \n",
       "2010-01-03  1.182046  1.368079  0.582621  0.535689  1.692577  0.252953   \n",
       "2010-01-04  1.182046  1.365861  0.581744  0.539248  1.686646  0.252863   \n",
       "2010-01-05  1.182046  1.377001  0.577825  0.538629  1.647656  0.253997   \n",
       "\n",
       "                 HUM       SNA       EMR       CAT  ...      INTC       KDP  \\\n",
       "Date                                                ...                       \n",
       "2010-01-01  0.917485  0.884942  0.890925  1.188501  ...  0.425942  0.592884   \n",
       "2010-01-02  0.917175  0.883859  0.890667  1.188759  ...  0.426922  0.591440   \n",
       "2010-01-03  0.916866  0.882776  0.890409  1.189017  ...  0.427902  0.589996   \n",
       "2010-01-04  0.916557  0.881693  0.890151  1.189275  ...  0.428882  0.588552   \n",
       "2010-01-05  0.944612  0.879424  0.894896  1.207841  ...  0.431976  0.597422   \n",
       "\n",
       "                 ADP       WMB       CCL      ATVI      DLTR       DLR  \\\n",
       "Date                                                                     \n",
       "2010-01-01  0.788448  0.360051  0.664106  0.233523  0.333867  1.033731   \n",
       "2010-01-02  0.788493  0.360219  0.664777  0.232904  0.333815  1.035587   \n",
       "2010-01-03  0.788538  0.360387  0.665447  0.232285  0.333764  1.037444   \n",
       "2010-01-04  0.788583  0.360555  0.666118  0.231666  0.333712  1.039300   \n",
       "2010-01-05  0.772464  0.361733  0.665911  0.231873  0.330343  1.032080   \n",
       "\n",
       "                  FE      ODFL  \n",
       "Date                            \n",
       "2010-01-01  0.974267  0.189025  \n",
       "2010-01-02  0.970089  0.188566  \n",
       "2010-01-03  0.965912  0.188108  \n",
       "2010-01-04  0.961735  0.187650  \n",
       "2010-01-05  0.962353  0.178298  \n",
       "\n",
       "[5 rows x 480 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial inputs\n",
    "\n",
    "root_dir          = r'C:\\Users\\wsteynber\\_Data Science'\n",
    "# root_dir          = r'c:\\Users\\Zoli\\Downloads\\python\\academy'\n",
    "\n",
    "with open(root_dir + r'\\dict_ts_alt_port.pkl' ,'rb') as handle:\n",
    "    dict_ts_alt_port = pickle.load(handle)\n",
    "\n",
    "df_market_port = dict_ts_alt_port['market_port']\n",
    "df_market_port.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc19e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_prediciton(_df ,_resampling='None'):\n",
    "    \"\"\"\n",
    "    spit the last one year from data frame (input: _df)\n",
    "    we assumed that data is daily\n",
    "    input:\n",
    "        _df, input data frame in time series format (index is time, one column with data)\n",
    "        _resampling='None' could be 'None', '1W' or '1M', ie. scales down horizon accordingly\n",
    "    outputs:\n",
    "        df_train, df_test: splited _df\n",
    "    \"\"\"\n",
    "\n",
    "    # params\n",
    "    if _resampling == '1M':\n",
    "        horizons = 12\n",
    "    elif _resampling == '1W':\n",
    "        horizons = 52\n",
    "    elif _resampling == 'None':\n",
    "        horizons = 365\n",
    "    else:\n",
    "        # todo proper error handling, now default is used\n",
    "        horizons = 365\n",
    "\n",
    "    split_point = _df.shape[0] - horizons\n",
    "    df_train, df_test = _df[:split_point],_df[split_point:]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "186078d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_df_prediciton' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wsteynber\\_Data Science\\OPA_repo\\004_timeseries_create_models.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wsteynber/_Data%20Science/OPA_repo/004_timeseries_create_models.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_train, df_test \u001b[39m=\u001b[39m split_df_prediciton(df_market_port, _resampling\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsteynber/_Data%20Science/OPA_repo/004_timeseries_create_models.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsteynber/_Data%20Science/OPA_repo/004_timeseries_create_models.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(df_train, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_df_prediciton' is not defined"
     ]
    }
   ],
   "source": [
    "df_train, df_test = split_df_prediciton(df_market_port, _resampling='None')\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df_train, label='train')\n",
    "plt.plot(df_test, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_analysis(_df, _resampling='1W', _debug=False, _method = 0, _plot = True, \n",
    "                _export = False, \n",
    "                _export_filename='ts_model_save.sav'):\n",
    "    \"\"\"\n",
    "    classicial time series method used on dataframe, provides charts, prediction, and calculates RMSE\n",
    "    inputs:\n",
    "        _df_ = df_market_port input data frame\n",
    "\n",
    "        _resampling = 'M', frequency of resampling, could be 1M, 1W, etc\n",
    "        _debug=True , if true additional plots have been shown\n",
    "        _method = 0, not used\n",
    "        _plot = True, if True, function displays plot, otherwise not\n",
    "        _export = False, if True model (after fit) will be saved to _export_filename\n",
    "        _export_filename name of the file used of saving model if _export = True\n",
    "           \n",
    "    output: RMSE of the prediction\n",
    "    \"\"\"\n",
    "    # params\n",
    "    if _resampling == '1M':\n",
    "        lags = 36 # 3 months\n",
    "        steps = 12\n",
    "    elif _resampling == '1W':\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "    else:\n",
    "        # todo proper error handling, now default is used\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "    \n",
    "    # train test split\n",
    "    df_train, df_test = split_df_prediciton(_df, _resampling='None')\n",
    "\n",
    "    # resampling \n",
    "    df_train_resampled = df_train.resample(_resampling).mean() \n",
    "    df_test_resampled = df_test.resample(_resampling).mean()\n",
    "    \n",
    "    # overwrite steps\n",
    "    steps = df_test_resampled.shape[0]\n",
    "    \n",
    "    # plot - if _debug is True\n",
    "    if _debug == True:\n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.plot(df_train_resampled);\n",
    "\n",
    "        tsa =seasonal_decompose(df_train_resampled)\n",
    "        fig=tsa.plot()\n",
    "        fig.set_size_inches((16, 8))\n",
    "        fig.tight_layout()\n",
    "        plt.show();\n",
    "    \n",
    "    # log transform + diffs\n",
    "    df_train_resampled_log = np.log(df_train_resampled) \n",
    "\n",
    "    df_train_resampled_log_1 = df_train_resampled_log.diff().dropna()\n",
    "    \n",
    "    if _debug == True:\n",
    "        pd.plotting.autocorrelation_plot(df_train_resampled_log_1);\n",
    "        res=sm.tsa.stattools.adfuller(df_train_resampled_log_1)\n",
    "        print (\"First order diff transformation p-value:\",res[1])\n",
    "\n",
    "\n",
    "    df_train_resampled_log_2 = df_train_resampled_log_1.diff().dropna()\n",
    "    if _debug == True:\n",
    "        pd.plotting.autocorrelation_plot(df_train_resampled_log_2);\n",
    "        res=sm.tsa.stattools.adfuller(df_train_resampled_log_2)\n",
    "        print (\"Second order diff transformation p-value:\",res[1])\n",
    "    \n",
    "    # auto correlation functions of second order diff\n",
    "    if _debug == True:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n",
    "        \n",
    "        plot_acf(df_train_resampled_log_2,lags = lags,ax=ax1)  ## was 36 in case on 1M\n",
    "        plot_pacf(df_train_resampled_log_2,lags = lags,ax=ax2) ## was 36 in case on 1M\n",
    "        \n",
    "        plt.show();\n",
    "    \n",
    "    # SARIMA fit default: (1,1,1)\n",
    "    model_sm = sm.tsa.SARIMAX(df_train_resampled_log, order=(1,1,1), seasonal_order = (1,1,1 ,steps))  ## 1M: seasonal_order = (0,1,1,12)\n",
    "    model_sm_fitted = model_sm.fit()\n",
    "    print(model_sm_fitted.summary())\n",
    "    \n",
    "    # export model\n",
    "    if _export == True:\n",
    "        pickle.dump(model_sm_fitted, open(root_dir + '\\\\' + _export_filename, 'wb'))\n",
    "\n",
    "    # Forecasting with a confidence interval    \n",
    "    prediction_log = model_sm_fitted.get_forecast(steps = steps).summary_frame()  \n",
    "    prediction = np.exp(prediction_log)\n",
    "\n",
    "    if _plot == True:\n",
    "        fig, ax = plt.subplots(figsize = (15,5))\n",
    "\n",
    "        plt.plot(df_train_resampled, label = \"train\")\n",
    "        plt.plot(df_test_resampled, label = \"test\")\n",
    "\n",
    "        prediction['mean'].plot(ax = ax, style = 'k--', label = \"prediction\") # Plotting the mean\n",
    "\n",
    "        ax.fill_between(prediction.index, prediction['mean_ci_lower'], prediction['mean_ci_upper'], color='k', alpha=0.1); \n",
    "        plt.axvline(x= df_test.index[0], color='orange'); \n",
    "        plt.legend()\n",
    "    \n",
    "    # calculate RMSE\n",
    "    rmse =  np.sqrt(mean_squared_error(df_test_resampled, prediction['mean']))\n",
    "    \n",
    "    return np.round(rmse,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ca52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_analysis(df_market_port, _resampling = '1W', _debug = False, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a800099",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_analysis(df_market_port, _resampling = '1M', _debug = False, _plot = True, _export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check export\n",
    "\n",
    "_export_filename='ts_model_save.sav'\n",
    "    \n",
    "loaded_model = pickle.load(open(root_dir + '\\\\' + _export_filename, 'rb'))\n",
    "print(loaded_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c30264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_analysis(_df, _resampling='1W', _debug=False, _method = 0, _plot = True,\n",
    "                 _export = False, \n",
    "                _export_filename='lin_model_save.sav'):\n",
    "    \"\"\"\n",
    "    linear regression method based forecast used on dataframe, provides charts, prediction, and calculates RMSE\n",
    "    inputs:\n",
    "        _df_ = df_market_port input data frame\n",
    "\n",
    "        _resampling = 'M', frequency of resampling, could be 1M, 1W, etc\n",
    "        _debug=True , if true additional plots have been shown\n",
    "        _method = 0 , 0: RandomForestRegressior, 1: Naiv, 2: Sesional naiv, 3: direct with RFR\n",
    "        _plot = True, if True, function displays plot, otherwise not\n",
    "        _export = False, if True model (after fit) will be saved to _export_filename, works only with method 0 !\n",
    "        _export_filename name of the file used of saving model if _export = True\n",
    "           \n",
    "    output: RMSE of the prediction\n",
    "    \"\"\"\n",
    "    # params\n",
    "    if _resampling == '1M':\n",
    "        lags = 36 # 3 months TODO: lags is not used, but should be instead of steps\n",
    "        steps = 12\n",
    "    elif _resampling == '1W':\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "    else:\n",
    "        # todo proper error handling, now default is used\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "\n",
    "    # resampling\n",
    "    df_resampled = _df.resample(_resampling).mean() \n",
    "    \n",
    "    # create data frame\n",
    "    df_lin = pd.DataFrame(df_resampled,index=df_resampled.index)\n",
    "    df_lin['Time'] = np.arange(len(df_lin.index))\n",
    "    df_lin.columns = ['Stock','Time']\n",
    "    \n",
    "    # create month/year as variable\n",
    "    df_lin['Month'] = df_lin.index.month\n",
    "    df_lin['Year'] = df_lin.index.year\n",
    "    \n",
    "    # create lags as variable\n",
    "    for i in range(12,18,1):\n",
    "        df_lin['Lag_'+ str(i)] = df_lin.Stock.shift(i)\n",
    "    df_lin['Lag_24'] = df_lin.Stock.shift(24)\n",
    "    \n",
    "    # remove nan-s due to lags\n",
    "    df_lin = df_lin.dropna(axis=0)\n",
    "\n",
    "    # train test split\n",
    "    df_train_lin, df_test_lin = split_df_prediciton(df_lin,_resampling = _resampling)\n",
    "    \n",
    "    # overwrite steps -- TODO not used, remove\n",
    "    steps = df_test_lin.shape[0]\n",
    "\n",
    "    # split of target variables from features\n",
    "    X_train = df_train_lin[df_train_lin.columns[2:]] ## 2 is used because Time column is there, otherwise 1\n",
    "    y_train = df_train_lin['Stock']\n",
    "    \n",
    "    # split of target variables from features\n",
    "    X_test = df_test_lin[df_test_lin.columns[2:]] ## 2 is used because Time column is there, otherwise 1\n",
    "    y_test = df_test_lin['Stock']\n",
    "    \n",
    "    if _method == 0:\n",
    "        # Random forest regressor\n",
    "        \n",
    "        # model\n",
    "        model = RandomForestRegressor(n_estimators=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # export model\n",
    "        if _export == True:\n",
    "            pickle.dump(model, open(root_dir + '\\\\' + _export_filename, 'wb'))\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # plot feature importance\n",
    "        if _debug == True:\n",
    "            feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "            feat_importances.nlargest(15).sort_values().plot(kind='barh', title='Feature Importance');\n",
    "\n",
    "        rmse =  np.sqrt(mean_squared_error(y_test, y_pred)) \n",
    "\n",
    "        # for plot:\n",
    "        y_pred_plot = y_pred\n",
    "        y_pred_legend = 'Random Forest Regressor'\n",
    "        \n",
    "    elif _method == 1:\n",
    "        # naiv approach\n",
    "        \n",
    "        forecast = np.mean(df_train_lin['Stock'][-lags:]) # was 24 \n",
    "        y_pred_mean = np.ones(steps,)*forecast # was 12\n",
    "\n",
    "        rmse =  np.sqrt(mean_squared_error(y_test, y_pred_mean)) \n",
    "\n",
    "        # for plot:\n",
    "        y_pred_plot = y_pred_mean\n",
    "        y_pred_legend = 'Naiv approach'\n",
    "\n",
    "    elif _method == 2:\n",
    "        # sesional\n",
    "        \n",
    "        y_pred_seas = df_train_lin['Stock'][-steps:] # was 12\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_seas))\n",
    "\n",
    "        # for plot:\n",
    "        y_pred_plot = y_pred_seas\n",
    "        y_pred_legend = 'Benchmark Seasonal naive'\n",
    "        \n",
    "    elif _method == 3:\n",
    "        for i in range(1,steps,1): # was 12 but it works with 1M only\n",
    "            df_lin['Lag_'+str(i)] = df_lin.Stock.shift(i)\n",
    "        \n",
    "        horizons = steps\n",
    "        cutoff_index = df_lin.shape[0]-horizons\n",
    "\n",
    "        predictions = []\n",
    "        pred_index = []\n",
    "        y_true_m3 = []\n",
    "        \n",
    "        for h in np.arange(1,horizons+1,1):\n",
    "            train, test = df_lin[(steps*2):cutoff_index], df_lin[cutoff_index:cutoff_index+h] # was 24\n",
    "            if h != 1:\n",
    "                if _debug == True:\n",
    "                    print(\"Horizon: \", h)\n",
    "                    print(\"Columns: \", df_lin.columns[1:-h+1])\n",
    "                    print(\"\")\n",
    "                X_train_m3 = train[df_lin.columns[1:-h+1]]\n",
    "                X_test_m3 = test[df_lin.columns[1:-h+1]]\n",
    "            else: \n",
    "                if _debug == True:\n",
    "                    print(\"Horizon: \", h)\n",
    "                    print(\"Columns: \", df_lin.columns[1:])\n",
    "                X_train_m3 = train[df_lin.columns[1:]]\n",
    "                X_test_m3 = test[df_lin.columns[1:]]\n",
    "                \n",
    "            y_train_m3 = train['Stock']\n",
    "            y_test_m3 = test['Stock']\n",
    "            \n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            model.fit(X_train_m3, y_train_m3)\n",
    "            \n",
    "            y_pred_m3 = model.predict(X_test_m3)\n",
    "            predictions.append(y_pred_m3[h-1])\n",
    "            pred_index.append(X_test_m3.index[h-1])\n",
    "            y_true_m3.append(y_test_m3[h-1])\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_m3, predictions))\n",
    "\n",
    "        y_pred_plot = predictions\n",
    "        y_pred_legend = 'Direct approach with Random Forest Regressor'\n",
    "        \n",
    "    else:\n",
    "        # do nothing, should drop an error\n",
    "        rmse = 0\n",
    "        \n",
    "        y_pred_plot = y_test\n",
    "        y_pred_legend = 'Empty method'\n",
    "\n",
    "    \n",
    "    # plot\n",
    "    if _plot == True:\n",
    "        fig, ax = plt.subplots(figsize = (15,5))\n",
    "\n",
    "        plt.plot(df_train_lin.index, df_train_lin.Stock, c='b', label='train')\n",
    "        plt.plot(X_test.index, y_test, c='orange', label='test')\n",
    "        plt.plot(X_test.index, y_pred_plot, c = 'r', label='prediction')\n",
    "        plt.axvline(x= df_test_lin.index[0], color='orange'); \n",
    "        plt.legend()\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Stock')\n",
    "        plt.title(y_pred_legend)\n",
    "        plt.show()\n",
    "    \n",
    "    return np.round(rmse,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_analysis(df_market_port, _resampling = '1M', _debug = False, _method = 0, _plot = True, _export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check export\n",
    "_export_filename='lin_model_save.sav'\n",
    "    \n",
    "loaded_model = pickle.load(open(root_dir + '\\\\' + _export_filename, 'rb'))\n",
    "\n",
    "# create data frame again\n",
    "df_resampled = df_market_port.resample('1M').mean() \n",
    "\n",
    "# create data frame\n",
    "df_lin = pd.DataFrame(df_resampled,index=df_resampled.index)\n",
    "df_lin['Time'] = np.arange(len(df_lin.index))\n",
    "df_lin.columns = ['Stock','Time']\n",
    "\n",
    "# create month/year as variable\n",
    "df_lin['Month'] = df_lin.index.month\n",
    "df_lin['Year'] = df_lin.index.year\n",
    "\n",
    "# create lags as variable\n",
    "for i in range(12,18,1):\n",
    "    df_lin['Lag_'+ str(i)] = df_lin.Stock.shift(i)\n",
    "df_lin['Lag_24'] = df_lin.Stock.shift(24)\n",
    "\n",
    "# remove nan-s due to lags\n",
    "df_lin = df_lin.dropna(axis=0)\n",
    "\n",
    "# train test split\n",
    "df_train_lin, df_test_lin = split_df_prediciton(df_lin,_resampling = '1M')\n",
    "\n",
    "X_test = df_test_lin[df_test_lin.columns[2:]] ## 2 is used because Time column is there, otherwise 1\n",
    "y_test = df_test_lin['Stock']\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    " \n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_analysis(df_market_port, _resampling = '1W', _debug = False, _method = 0, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_analysis(df_market_port, _resampling = '1M', _debug = False, _method = 1, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_analysis(df_market_port, _resampling = '1M', _debug = False, _method = 2, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_analysis(df_market_port, _resampling = '1M', _debug = False, _method = 3, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_analysis(_df, _resampling='1W', _debug=False, _method = 0, _plot = True,\n",
    "                 _export = False, \n",
    "                _export_filename='pt_model_save.sav'):\n",
    "    \"\"\"\n",
    "    Prophet forecast used on dataframe, provides charts, prediction, and calculates RMSE\n",
    "    inputs:\n",
    "        _df_ = df_market_port input data frame\n",
    "\n",
    "        _resampling = 'M', frequency of resampling, could be 1M, 1W, etc\n",
    "        _debug=True , if true additional plots have been shown\n",
    "        _method = 0 , not used\n",
    "        _plot = True, if True, function displays plot, otherwise not\n",
    "        _export = False, if True model (after fit) will be saved to _export_filename,\n",
    "        _export_filename name of the file used of saving model if _export = True\n",
    "           \n",
    "    output: RMSE of the prediction\n",
    "    \"\"\"\n",
    "    # params\n",
    "    if _resampling == '1M':\n",
    "        lags = 36 # 3 months TODO: lags is not used, but should be instead of steps\n",
    "        steps = 12\n",
    "        freq = 'MS'\n",
    "    elif _resampling == '1W':\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "        freq = 'W'\n",
    "    else:\n",
    "        # todo proper error handling, now default is used\n",
    "        lags = 156\n",
    "        steps = 52\n",
    "\n",
    "    # resampling\n",
    "    df_resampled = _df.resample(_resampling).mean() \n",
    "    \n",
    "    # create data frame ---- train\n",
    "    df_pt = pd.DataFrame(df_resampled, index=df_resampled.index)\n",
    "    df_pt['ds'] = df_pt.index\n",
    "    df_pt.columns = ['y','ds']\n",
    "\n",
    "    if _debug == True:\n",
    "        print(df_pt.head())\n",
    "       \n",
    "    # remove nan-s -- not needed\n",
    "    #df_pt = df_pt.dropna(axis=0)\n",
    "\n",
    "    # train test split\n",
    "    df_train_pt, df_test_pt = split_df_prediciton(df_pt,_resampling = _resampling)\n",
    "    \n",
    "    # overwrite steps -- TODO check\n",
    "    steps = df_test_pt.shape[0]\n",
    "\n",
    "    # model creation and fit\n",
    "    model_pt = pt.Prophet(interval_width=0.95)\n",
    "    model_pt.fit(df_train_pt)\n",
    "    # INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
    "    # INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
    "    \n",
    "    # export model\n",
    "    if _export == True:\n",
    "        pickle.dump(model_pt, open(root_dir + '\\\\' + _export_filename, 'wb'))\n",
    "    \n",
    "    # prediction df_market_port\n",
    "    future_dates = model_pt.make_future_dataframe(periods = steps, freq = freq) # TODO MS ws montlhy?\n",
    "    \n",
    "    # prediction\n",
    "    forecast = model_pt.predict(future_dates)\n",
    "    \n",
    "    # plot model component\n",
    "    if _debug == True: \n",
    "        model_pt.plot_components(forecast)\n",
    "\n",
    "    if _debug == True:\n",
    "        forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()\n",
    "\n",
    "    # model plot\n",
    "    if _plot == True:\n",
    "        model_pt.plot(forecast, uncertainty=True,figsize = (15,5))\n",
    "\n",
    "        #ax = y_save.plot()\n",
    "        plt.plot(df_test_pt.index, df_test_pt['y'], c='orange', label='test')\n",
    "        plt.axvline(x= df_test_pt.index[0], color='orange'); \n",
    "\n",
    "    # RSME calculation\n",
    "    rmse =  np.sqrt(mean_squared_error(df_test_pt['y'], forecast.trend.tail(steps)))\n",
    "    \n",
    "    return np.round(rmse,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_analysis(df_market_port, _resampling = '1M', _debug = False, _method = 0, _plot = True, _export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10648464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check export\n",
    "_export_filename='pt_model_save.sav'\n",
    "    \n",
    "loaded_model = pickle.load(open(root_dir + '\\\\' + _export_filename, 'rb'))\n",
    "# prediction DF\n",
    "future_dates = loaded_model.make_future_dataframe(periods = 12, freq = 'MS') \n",
    "\n",
    "# prediction\n",
    "forecast = loaded_model.predict(future_dates)\n",
    "\n",
    "# plot model component\n",
    "loaded_model.plot_components(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a621c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_analysis(df_market_port, _resampling = '1W', _debug = False, _method = 0, _plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f10562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepl_analysis(_df, _resampling='1W', _debug=False, _method = 0, _plot = True,\n",
    "                 _export = False, \n",
    "                _export_filename='dl_model_save.sav'):\n",
    "    \"\"\"\n",
    "    deep learning forecast used on dataframe, provides charts, prediction, and calculates RMSE\n",
    "    inputs:\n",
    "        _df_ = df_market_port input data frame\n",
    "\n",
    "        _resampling = 'M', frequency of resampling, could be 1M, 1W, etc\n",
    "        _debug=True , if true additional plots have been shown\n",
    "        _method = 0 , not used\n",
    "        _plot = True, if True, function displays plot, otherwise not\n",
    "        _export = False, if True model (after fit) will be saved to _export_filename,\n",
    "        _export_filename name of the file used of saving model if _export = True\n",
    "           \n",
    "    output: RMSE of the prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO DL part\n",
    "    \n",
    "    # RSME calculation\n",
    "    rmse =  0 \n",
    "    \n",
    "    return np.round(rmse,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf24da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# NOTHING HAS BEEN DONE TO ANY CODE FURTHER BELOW\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae27ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class can be used as standardized output of all analysis functions, including data for plot\n",
    "# TODO conflicts with built in plots\n",
    "# TODO lin reg\n",
    "class result_analysis:\n",
    "    def __init__(self, rsme, pred, pred_ci_l, pred_ci_u, df_train):\n",
    "        self.rsme = rsme\n",
    "        self.prediction_mean = pred\n",
    "        self.prediction_ci_lower = pred_ci_l\n",
    "        self.prediction_ci_upper = pred_ci_u\n",
    "        self.df_train = df_train # resampled\n",
    "        self.df_test = df_test # resampled\n",
    "        #df_test.index[0] \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
