{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["DATA COLLECTION AND AGGREGATIONS:<br><br>\n","This step first looked at the kaggel datset and saved the company attributes in a pkl file.\n","However after observing that the data was not up to date this pkl file is updated in the cleaning script (1_cleaning_qualitative_data.ipynb)\n","\n","(Kindly note that  we have both a py (to help investigate and debug)\n","and a final ipynb file for the data aggregation and cleaning steps)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","import yfinance as yf\n","\n","directory = r'C:\\Users\\49176\\Desktop\\DSA\\OPA_repo\\Data\\csv'\n","sp_data_ticker = list()\n","for f in os.listdir(directory):\n","    f_path = os.path.join(directory, f)\n","    if os.path.isfile(f_path):\n","        sp_data_ticker.append(f[:-4])\n","        #print(f_path)\n","        #print(sp_data_ticker)\n","yf_ticker_df = pd.read_excel(r'C:\\Users\\49176\\Desktop\\DSA\\OPA_repo\\Data\\tickers_usa.ods', engine='odf')\n","yf_ticker = list(yf_ticker_df.Ticker)\n","\n","print('check if all data tickers are in yfinace ticker list:', set(sp_data_ticker) - set(yf_ticker) == set())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#aggregate all the ticker info\n","df_allInfo = pd.DataFrame([])\n","for t in sp_data_ticker:\n","    temp_df = pd.DataFrame.from_dict([yf.Ticker(t).info]) \n","    df_allInfo = pd.concat([df_allInfo, temp_df])\n","\n","df_allInfo.to_pickle(r'C:\\Users\\49176\\Desktop\\DSA\\OPA_repo\\df_allInfo_124.pkl')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#not all tickers were getting picked up\n","#hence these steps for handling incompatible inputs\n","issue_tickers = []\n","for t in list(set(sp_data_ticker) - set(df_allInfo.symbol)):\n","    try:\n","        temp_df = pd.DataFrame.from_dict([yf.Ticker(t).info]) \n","        df_allInfo = pd.concat([df_allInfo, temp_df])\n","    except:\n","        issue_tickers.append(t)\n","        continue\n","\n","#['REGN', 'TJX', 'TRAUF'] are the issue tickers -> we will manually append them\n","df_allInfo = pd.concat([df_allInfo, pd.DataFrame.from_dict([yf.Ticker('REGN').info])])\n","df_allInfo = pd.concat([df_allInfo, pd.DataFrame.from_dict([yf.Ticker('TJX').info])])\n","df_allInfo = pd.concat([df_allInfo, pd.DataFrame.from_dict([yf.Ticker('TRAUF').info])])\n","#the manual append works fine, api call times could have been an issue why it threw an exception\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_allInfo.to_pickle(r'C:\\Users\\49176\\Desktop\\DSA\\OPA_repo\\df_allInfo.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#---------------------------------------------------------------------------------------------------------------\n","#THIS NEXT step was done after running the cleaning script resulting in df_allInfo_clean.pkl\n","#which contains all up to date 503 tickers with their compyny attributes.\n","#---------------------------------------------------------------------------------------------------------------\n","\n","df = pd.read_pickle(r'C:\\Users\\49176\\Desktop\\DSA\\OPA_repo\\df_allInfo_clean.pkl')\n","ticker_str = \" \".join(list(df.index))\n","data = yf.download(ticker_str, start=\"1900-01-01\",  #max 50 yrs data is only available so 1962-01-02\n","                    end=\"2022-12-10\", group_by='tickers')\n","data.to_pickle('50yr_timeSeries_data.pkl')\n","\n"]}],"metadata":{"kernelspec":{"display_name":".opa_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1a9e40b8b4ac1496d3cd47ca77c2445f878e9ec535527af5083f656080d0d66a"}}},"nbformat":4,"nbformat_minor":2}
